# Agent Design and State Summary

This document summarizes the design, decisions, and current state of the `mollerdb` project as of the last interaction. It is intended to provide context for future AI agents or developers to seamlessly continue the work.

**Last Updated:** 2025-11-01 18:08:26 UTC
**Last User:** Copilot Agent (via wdconinc)

## 1. Project Goal

The primary goal is to create a high-performance, dual-language Software Development Kit (SDK) to provide convenient access to the MOLLER experiment's analysis database. This SDK is a key component of a larger strategy to improve data accessibility for collaborators who may not be proficient in SQL.

## 2. Core Design Decisions

### 2.1. Overall SDK Architecture
The SDK will support both C++ and Python users without duplicating core logic. The chosen architecture is:
- **C++ Core Library (`libmollerdb`)**: A central, high-performance C++ library that contains all database interaction logic.
- **Python Bindings**: A thin wrapper around the C++ core, exposing its functionality to Python.

### 2.2. Key Technologies
- **Build System**: `scikit-build-core` was chosen as the modern PEP 517 build backend. It will orchestrate the build process by invoking CMake. This replaces an earlier suggestion of using `setuptools` with a custom `CMakeBuild` class.
- **C++ Database Driver**: `sqlpp23` is the designated library for connecting to and interacting with the PostgreSQL database from C++. It was chosen over `libpqxx` because it is a header-only library with fewer dependencies, making it more platform-independent and easier to manage. It will be included as a git submodule.
- **Python Bindings**: `pybind11` is the standard tool chosen to create the bindings between C++ and Python.
- **Data Interchange Format**: **Apache Arrow** was identified as the critical technology for efficient, zero-copy data transfer between the C++ core and Python. C++ functions will query the database and construct Arrow `Table` objects, which can be converted to Pandas DataFrames in Python with minimal overhead.

### 2.3. Naming and Structure
After some discussion, the following naming convention was finalized for consistency:
- **Repository**: `JeffersonLab/mollerdb`
- **Python Package Name**: `mollerdb`
- **Compiled Python Module**: `mollerdb` (This is the `.so` or `.pyd` file generated by `pybind11`).
- The final Python package structure will be located in `python/mollerdb/`.

## 3. Associated Database Schema Design

The SDK design was informed by a proposed redesign of the underlying database schema (`qwparity_schema.dbml`). Key schema suggestions include:
- **Unified Results Table**: Merging detector-specific tables (`md_data`, `lumi_data`, `beam`) into a single, flexible `results` table.
- **Generalized Sensitivities Table**: Abstracting "slopes" into a generic `sensitivities` table to store any linear correlation (detector-monitor, detector-detector, etc.). This requires a master `quantity` lookup table.
- **Versioning**: Adding versioning (e.g., `valid_from_run`, `valid_to_run`) to detector and quantity tables to ensure long-term reproducibility.

## 4. Documentation

### 4.1. Documentation Structure
The project documentation is located in the `docs/` directory and is published to GitHub Pages using Docsify. The documentation structure includes:
- **docs/README.md**: Main documentation file with installation and usage instructions
- **docs/_sidebar.md**: Sidebar navigation configuration
- **docs/index.html**: Docsify configuration file
- **docs/.nojekyll**: Disables Jekyll processing for GitHub Pages

### 4.2. Documentation Maintenance Guidelines
**IMPORTANT**: When developing new features or making changes, agents MUST keep the documentation up to date:

1. **When Adding New Features**:
   - Update `docs/README.md` with usage examples for the new feature
   - Add API reference documentation for new classes/methods
   - Update installation instructions if new dependencies are required
   - Add to the appropriate section in `docs/_sidebar.md` if creating new documentation pages

2. **When Modifying Existing Features**:
   - Update all affected examples in `docs/README.md`
   - Ensure API reference documentation reflects the changes
   - Update any affected usage instructions

3. **Periodic Documentation Review**:
   - Before completing major features, review the documentation for accuracy
   - Verify that all code examples are correct and runnable
   - Check that installation instructions are current
   - Ensure API reference documentation matches the actual implementation

4. **Documentation Testing**:
   - When making significant documentation changes, verify that:
     - All code examples are syntactically correct
     - Installation instructions work on supported platforms
     - Links to external resources are valid
     - The docsify sidebar navigation works correctly

The documentation is automatically deployed to GitHub Pages via the `.github/workflows/pages.yml` workflow when changes are pushed to the main branch.

## 5. Current Status and Next Steps

**Once the repository is populated, the project can proceed with:**
1.  **Implementing Core Logic**: Flesh out the `src/Database.cpp` file to perform actual database queries using `sqlpp23`.
2.  **Integrating Apache Arrow**: Add the logic to build Arrow `Table` objects from the query results and implement the C++-to-Python type conversions for these tables.
3.  **CI/CD Setup**: Create a GitHub Actions workflow to build and test the C++ and Python components on various platforms, ensuring all dependencies (`arrow`) are correctly handled. The workflow must ensure git submodules are checked out to provide `sqlpp23`.
4.  **Documentation and Examples**: Expand the `docs/README.md` and add an `examples/` directory showing how to use the SDK in both Python and C++.
